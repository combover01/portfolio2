---
title: LULL
date: 2024-03-12 16:18:00 Z
published: false
---

https://youtu.be/gclmTAKhYU0

LULL is an exploration of pulling or lulling an audience into a meditative space that is reflective of their own state through the use of brain waves. Written for saxophone, EEG, and electronics, LULL explores a historic brain music paradigm of sonifying alpha band readings (8-12 Hz) that has been utilized by composers/performers such as Pauline Oliveros, David Rosenboom, and Alvin Lucier. The performer engages in a feedback system, listening to their alpha feedback and performing alongside it as if their brainwaves were a duo partner.

The piece begins with a performer-led breathing practice for the audience using the box breathing method (in 4, hold 4, out 4, hold 4). Once the audience starts to enter their own meditation through the breathwork, the saxophonist begins to play an improvised melody. Effects such as doubling, reverb, and delay are adjusted live to fit the saxophonist's improvisations. The performer becomes aware of the state of their brain while trying to relax and stay within the musical meditation motif.
The sound of LULL is uniquely defined by the performer’s improvisational tendencies. Its midrange texture is created by the saxophone and a digitally doubled and transposed copy with reverb and delay that changes length throughout the piece. This is layered on top of a sawtooth drone that emulates a string section. The drone is triggered by the performer’s alpha waves throughout the performance.

An increase in the brain’s alpha frequency band (8-12 Hz) typically represents a state of relaxation and mindfulness. The performer creates peaks in their own alpha brainwaves and in doing so attempts to establish a feedback loop both with their brainwaves and the saxophone as well as with the performer and the audience. The audience’s meditation session is guided by the performer’s personal exploration of attaining a meditative flow state.

LULL uses electroencephalogram (EEG) signals in Max to augment and enhance a live saxophone performance. Established methods of streaming biosignals such as EEG into Max require proprietary software to send the stream over UDP, or additional software to convert a Lab Streaming Layer (LSL) stream to UDP \cite{openbci}. Relying on a second or third software outside of the Max environment provides room for bugs and errors that the user may not anticipate, such as the stream dropping or the software crashing during a performance, as well as requiring that the performer understand how to use all of the programs and how they work together. Once the stream makes it to Max, the biosignal needs to be filtered appropriately and is subject to noise. The background knowledge necessary for processing biosignals makes performing music with brainwaves a technical problem with a high barrier of entry for non-experts.

The BioSignal library is a new system for performing live brain music. It affords an ease of real-time EEG analysis in Max that can be readily translated into music. This new interface for musical expression (NIME) makes the brain an accessible musical controller. 
The library is a collection of Max externals that allows any biosignal amplifier which sends its data through Lab Streaming Layer (LSL) to flow directly into Max. It contains objects that upsample and filter the signal so it is ready to use in anyone’s Max patches.
 
The performer can use any EEG amplifier and headset to perform LULL as long as it can communicate using LSL. LSL compatibility and instructions to start an LSL stream are typically described on the EEG manufacturer’s website. In the Max patch, externals from the BioSignal library are used to receive the LSL stream and then to filter the total EEG signal into the alpha band (8-12 Hz). The power of the alpha band is used to trigger a drone when it exceeds a threshold with a retrigger timer of 5 seconds. The pitch of the drone is chosen randomly from a predetermined set of notes in the same scale. This is the home key for the saxophonist to improvise in. The drone sound is generated in Ableton, triggered by MIDI being sent from Max. It consists of a reverberated sawtooth/string sound generated by the Operator instrument.

SCORE:
[LULL score.pdf](/uploads/LULL%20score.pdf)


